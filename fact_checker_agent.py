# PATH: fact_checker_agent.py
"""
üîç FACT-CHECKER AGENT - V√©rificateur de V√©racit√© avec Sources Officielles
Con√ßu pour Cursor Agent Mode Auto
"""

import os
import json
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from urllib.parse import urlparse
import hashlib

# Core dependencies
import requests
from bs4 import BeautifulSoup
from pydantic import BaseModel, Field

# LangChain imports
from langchain.agents import AgentExecutor, create_openai_tools_agent
from langchain.tools import Tool, StructuredTool
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
from langchain.schema import SystemMessage, HumanMessage
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# For Cursor Agent compatibility
from dataclasses import dataclass
from enum import Enum


# ============================================
# CONFIGURATION
# ============================================

class Config:
    """Configuration centralis√©e pour l'agent"""
    
    # API Keys (√† configurer dans .env ou directement)
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "your-key-here")
    
    # Sources officielles de confiance (extensible)
    TRUSTED_SOURCES = {
        # Gouvernement FR
        "gouvernement.fr": {"score": 10, "type": "government"},
        "service-public.fr": {"score": 10, "type": "government"},
        "legifrance.gouv.fr": {"score": 10, "type": "legal"},
        
        # Organisations internationales
        "who.int": {"score": 9, "type": "health"},
        "un.org": {"score": 9, "type": "international"},
        "europa.eu": {"score": 9, "type": "government"},
        
        # Institutions scientifiques
        "nature.com": {"score": 8, "type": "scientific"},
        "science.org": {"score": 8, "type": "scientific"},
        "pubmed.ncbi.nlm.nih.gov": {"score": 9, "type": "medical"},
        
        # Fact-checkers reconnus
        "snopes.com": {"score": 7, "type": "factcheck"},
        "factcheck.org": {"score": 7, "type": "factcheck"},
        "politifact.com": {"score": 7, "type": "factcheck"},
        
        # M√©dias de r√©f√©rence
        "reuters.com": {"score": 6, "type": "news"},
        "apnews.com": {"score": 6, "type": "news"},
        "bbc.com": {"score": 6, "type": "news"},
        
        # Encyclop√©dies
        "britannica.com": {"score": 7, "type": "encyclopedia"},
        "wikipedia.org": {"score": 5, "type": "encyclopedia"},
    }
    
    # Headers pour les requ√™tes
    HEADERS = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # Param√®tres de l'agent
    MODEL_NAME = "gpt-4-turbo-preview"
    MAX_SEARCH_RESULTS = 5
    CHUNK_SIZE = 1000
    CHUNK_OVERLAP = 200


# ============================================
# MOD√àLES DE DONN√âES
# ============================================

class VerificationStatus(Enum):
    """Statuts de v√©rification"""
    VERIFIED = "‚úÖ V√âRIFI√â"
    PARTIALLY_VERIFIED = "‚ö†Ô∏è PARTIELLEMENT V√âRIFI√â"
    UNVERIFIED = "‚ùå NON V√âRIFI√â"
    CONTRADICTORY = "üîÑ CONTRADICTOIRE"
    INSUFFICIENT_DATA = "‚ùì DONN√âES INSUFFISANTES"


@dataclass
class FactClaim:
    """Repr√©sente une affirmation √† v√©rifier"""
    claim: str
    source: Optional[str] = None
    date: Optional[str] = None
    context: Optional[str] = None


@dataclass
class SourceEvidence:
    """Preuve trouv√©e dans une source"""
    url: str
    domain: str
    trust_score: float
    content: str
    supports_claim: bool
    confidence: float
    extraction_date: str


@dataclass
class VerificationResult:
    """R√©sultat complet de v√©rification"""
    claim: FactClaim
    status: VerificationStatus
    confidence_score: float
    official_sources: List[SourceEvidence]
    other_sources: List[SourceEvidence]
    analysis: str
    recommendations: List[str]


# ============================================
# OUTILS DE SCRAPING ET ANALYSE
# ============================================

class WebScraper:
    """Outil de scraping web intelligent"""
    
    @staticmethod
    def scrape_url(url: str) -> Dict[str, Any]:
        """Scrape une URL et extrait le contenu pertinent"""
        try:
            response = requests.get(url, headers=Config.HEADERS, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Supprime scripts et styles
            for script in soup(["script", "style"]):
                script.decompose()
            
            # Extraction du texte principal
            text = soup.get_text(separator=' ', strip=True)
            
            # M√©tadonn√©es
            title = soup.find('title').text if soup.find('title') else ''
            meta_desc = ''
            if soup.find('meta', {'name': 'description'}):
                meta_desc = soup.find('meta', {'name': 'description'}).get('content', '')
            
            return {
                "url": url,
                "title": title,
                "description": meta_desc,
                "content": text[:5000],  # Limite pour l'efficacit√©
                "success": True
            }
            
        except Exception as e:
            return {
                "url": url,
                "error": str(e),
                "success": False
            }
    
    @staticmethod
    def search_google(query: str, num_results: int = 5) -> List[str]:
        """Recherche Google (simul√©e - remplacer par API r√©elle en prod)"""
        # Pour Cursor : utilise DuckDuckGo comme alternative
        try:
            from duckduckgo_search import DDGS
            
            with DDGS() as ddgs:
                results = list(ddgs.text(query, max_results=num_results))
                return [r['href'] for r in results]
        except:
            # Fallback : URLs de d√©mo
            return [
                f"https://example.com/result_{i}" 
                for i in range(num_results)
            ]


class TrustAnalyzer:
    """Analyse la fiabilit√© des sources"""
    
    @staticmethod
    def calculate_trust_score(url: str) -> Tuple[float, str]:
        """Calcule un score de confiance pour une URL"""
        domain = urlparse(url).netloc.lower()
        
        # V√©rifie les sources officielles
        for trusted_domain, info in Config.TRUSTED_SOURCES.items():
            if trusted_domain in domain:
                return info['score'] / 10.0, info['type']
        
        # Score par d√©faut pour sources non list√©es
        if '.gov' in domain or '.gouv' in domain:
            return 0.8, 'government'
        elif '.edu' in domain or '.ac.' in domain:
            return 0.7, 'academic'
        elif '.org' in domain:
            return 0.5, 'organization'
        else:
            return 0.3, 'unknown'
    
    @staticmethod
    def extract_relevant_content(text: str, claim: str) -> str:
        """Extrait le contenu pertinent par rapport √† la claim"""
        # Tokenisation simple
        claim_words = set(claim.lower().split())
        sentences = text.split('.')
        
        relevant_sentences = []
        for sentence in sentences:
            sentence_words = set(sentence.lower().split())
            # Score de pertinence basique
            overlap = len(claim_words & sentence_words)
            if overlap > 2:  # Seuil de pertinence
                relevant_sentences.append(sentence.strip())
        
        return '. '.join(relevant_sentences[:10])  # Max 10 phrases


# ============================================
# OUTILS LANGCHAIN
# ============================================

def create_fact_checking_tools():
    """Cr√©e les outils pour l'agent LangChain"""
    
    def search_and_scrape(query: str) -> str:
        """Recherche et scrape des informations sur le web"""
        scraper = WebScraper()
        urls = scraper.search_google(query, Config.MAX_SEARCH_RESULTS)
        
        results = []
        for url in urls:
            data = scraper.scrape_url(url)
            if data['success']:
                trust_score, source_type = TrustAnalyzer.calculate_trust_score(url)
                results.append({
                    'url': url,
                    'title': data['title'],
                    'content': data['content'][:500],
                    'trust_score': trust_score,
                    'source_type': source_type
                })
        
        return json.dumps(results, indent=2, ensure_ascii=False)
    
    def verify_with_official_sources(claim: str) -> str:
        """V√©rifie sp√©cifiquement avec les sources officielles"""
        scraper = WebScraper()
        analyzer = TrustAnalyzer()
        
        # Recherche cibl√©e sur sources officielles
        official_results = []
        for domain in list(Config.TRUSTED_SOURCES.keys())[:5]:
            query = f"site:{domain} {claim}"
            urls = scraper.search_google(query, 2)
            
            for url in urls:
                data = scraper.scrape_url(url)
                if data['success']:
                    relevant_content = analyzer.extract_relevant_content(
                        data['content'], claim
                    )
                    if relevant_content:
                        official_results.append({
                            'domain': domain,
                            'url': url,
                            'relevant_content': relevant_content,
                            'trust_score': Config.TRUSTED_SOURCES[domain]['score']
                        })
        
        return json.dumps(official_results, indent=2, ensure_ascii=False)
    
    def analyze_credibility(sources_json: str) -> str:
        """Analyse la cr√©dibilit√© globale bas√©e sur les sources"""
        try:
            sources = json.loads(sources_json)
        except:
            sources = []
        
        if not sources:
            return "Aucune source disponible pour l'analyse"
        
        # Calcul du score de cr√©dibilit√© pond√©r√©
        total_score = 0
        total_weight = 0
        source_types = {}
        
        for source in sources:
            score = source.get('trust_score', 0)
            total_score += score
            total_weight += 1
            
            source_type = source.get('source_type', 'unknown')
            source_types[source_type] = source_types.get(source_type, 0) + 1
        
        avg_score = total_score / total_weight if total_weight > 0 else 0
        
        # Analyse
        analysis = {
            'average_trust_score': round(avg_score, 2),
            'num_sources': len(sources),
            'source_distribution': source_types,
            'credibility_level': 'HIGH' if avg_score > 0.7 else 'MEDIUM' if avg_score > 0.4 else 'LOW',
            'recommendation': 'Fiable' if avg_score > 0.7 else '√Ä v√©rifier' if avg_score > 0.4 else 'Peu fiable'
        }
        
        return json.dumps(analysis, indent=2, ensure_ascii=False)
    
    # Cr√©ation des outils
    tools = [
        Tool(
            name="search_and_scrape",
            func=search_and_scrape,
            description="Recherche et extrait des informations du web sur un sujet donn√©"
        ),
        Tool(
            name="verify_official_sources",
            func=verify_with_official_sources,
            description="V√©rifie une affirmation sp√©cifiquement avec des sources officielles et institutionnelles"
        ),
        Tool(
            name="analyze_credibility",
            func=analyze_credibility,
            description="Analyse la cr√©dibilit√© globale bas√©e sur les sources trouv√©es"
        )
    ]
    
    return tools


# ============================================
# AGENT PRINCIPAL
# ============================================

class FactCheckerAgent:
    """Agent principal de v√©rification des faits"""
    
    def __init__(self):
        """Initialise l'agent avec LangChain"""
        
        # LLM
        self.llm = ChatOpenAI(
            model=Config.MODEL_NAME,
            temperature=0.1,  # Basse pour plus de pr√©cision
            openai_api_key=Config.OPENAI_API_KEY
        )
        
        # Outils
        self.tools = create_fact_checking_tools()
        
        # Prompt syst√®me
        self.system_prompt = """
        Tu es un expert en v√©rification des faits (fact-checker) rigoureux et m√©thodique.
        
        Ta mission est de :
        1. V√©rifier la v√©racit√© des affirmations en utilisant des sources fiables
        2. Privil√©gier TOUJOURS les sources officielles et institutionnelles
        3. Fournir une analyse objective et nuanc√©e
        4. Indiquer clairement le niveau de confiance de tes conclusions
        
        M√©thodologie :
        1. D'ABORD chercher dans les sources officielles (gouvernement, ONU, OMS, etc.)
        2. ENSUITE √©largir aux sources acad√©miques et journalistiques r√©put√©es
        3. COMPARER les diff√©rentes sources et identifier les contradictions
        4. √âVALUER la cr√©dibilit√© globale
        5. CONCLURE avec un verdict clair et des recommandations
        
        Format de r√©ponse attendu :
        - VERDICT : [V√âRIFI√â / PARTIELLEMENT V√âRIFI√â / NON V√âRIFI√â / CONTRADICTOIRE]
        - CONFIANCE : [Score de 0 √† 100%]
        - SOURCES OFFICIELLES : [Liste avec citations]
        - ANALYSE : [Explication d√©taill√©e]
        - RECOMMANDATIONS : [Actions sugg√©r√©es]
        """
        
        # Prompt template
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", self.system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("user", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        
        # Agent
        self.agent = create_openai_tools_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=self.prompt
        )
        
        # Memory
        self.memory = ConversationBufferWindowMemory(
            memory_key="chat_history",
            return_messages=True,
            k=5  # Garde 5 derniers √©changes
        )
        
        # Executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,  # Pour debug dans Cursor
            max_iterations=5,
            early_stopping_method="generate"
        )
    
    def verify_claim(self, claim: str, context: str = "") -> Dict[str, Any]:
        """
        V√©rifie une affirmation
        
        Args:
            claim: L'affirmation √† v√©rifier
            context: Contexte additionnel optionnel
            
        Returns:
            Dictionnaire avec le r√©sultat de la v√©rification
        """
        
        # Construction de la requ√™te
        query = f"""
        AFFIRMATION √Ä V√âRIFIER :
        "{claim}"
        
        {f'CONTEXTE : {context}' if context else ''}
        
        Instructions :
        1. Recherche d'abord dans les sources officielles et gouvernementales
        2. Compare avec d'autres sources fiables
        3. Analyse la cr√©dibilit√© globale
        4. Fournis un verdict clair avec justifications
        """
        
        try:
            # Ex√©cution de l'agent
            result = self.agent_executor.run(query)
            
            # Post-traitement du r√©sultat
            return self._parse_result(result, claim)
            
        except Exception as e:
            return {
                "status": "ERROR",
                "error": str(e),
                "claim": claim,
                "message": "Une erreur est survenue lors de la v√©rification"
            }
    
    def _parse_result(self, raw_result: str, claim: str) -> Dict[str, Any]:
        """Parse et structure le r√©sultat brut de l'agent"""
        
        # Extraction basique des √©l√©ments cl√©s
        result = {
            "claim": claim,
            "raw_analysis": raw_result,
            "timestamp": datetime.now().isoformat(),
        }
        
        # D√©tection du verdict
        if "V√âRIFI√â" in raw_result.upper() and "NON V√âRIFI√â" not in raw_result.upper():
            if "PARTIELLEMENT" in raw_result.upper():
                result["verdict"] = VerificationStatus.PARTIALLY_VERIFIED.value
            else:
                result["verdict"] = VerificationStatus.VERIFIED.value
        elif "NON V√âRIFI√â" in raw_result.upper():
            result["verdict"] = VerificationStatus.UNVERIFIED.value
        elif "CONTRADICTOIRE" in raw_result.upper():
            result["verdict"] = VerificationStatus.CONTRADICTORY.value
        else:
            result["verdict"] = VerificationStatus.INSUFFICIENT_DATA.value
        
        # Extraction du score de confiance (recherche de pourcentages)
        import re
        confidence_match = re.search(r'(\d+)%', raw_result)
        if confidence_match:
            result["confidence"] = int(confidence_match.group(1))
        else:
            result["confidence"] = 50  # Par d√©faut
        
        return result
    
    def batch_verify(self, claims: List[str]) -> List[Dict[str, Any]]:
        """V√©rifie plusieurs affirmations en batch"""
        results = []
        for claim in claims:
            print(f"\nüîç V√©rification : {claim}")
            result = self.verify_claim(claim)
            results.append(result)
            print(f"‚úÖ Verdict : {result.get('verdict', 'UNKNOWN')}")
        
        return results


# ============================================
# INTERFACE CURSOR AGENT MODE
# ============================================

class CursorAgentInterface:
    """Interface optimis√©e pour Cursor Agent Mode"""
    
    @staticmethod
    def run_interactive():
        """Mode interactif pour Cursor"""
        print("""
        ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
        ‚ïë     üîç FACT-CHECKER AGENT - Cursor Edition üîç       ‚ïë
        ‚ïë                                                      ‚ïë
        ‚ïë  V√©rification automatique avec sources officielles  ‚ïë
        ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
        """)
        
        # V√©rifier la cl√© API
        if Config.OPENAI_API_KEY == "your-key-here":
            print("‚ö†Ô∏è  ATTENTION : Configure OPENAI_API_KEY dans le script ou .env")
            print("Pour continuer en mode d√©mo, appuie sur Enter...")
            input()
        
        # Initialisation de l'agent
        print("\nüöÄ Initialisation de l'agent...")
        agent = FactCheckerAgent()
        print("‚úÖ Agent pr√™t !\n")
        
        # Boucle interactive
        while True:
            print("\n" + "="*50)
            print("Entre une affirmation √† v√©rifier (ou 'quit' pour terminer) :")
            claim = input("üìù > ").strip()
            
            if claim.lower() in ['quit', 'exit', 'q']:
                print("\nüëã Au revoir !")
                break
            
            if not claim:
                continue
            
            # V√©rification
            print(f"\nüîç Analyse en cours pour : '{claim}'")
            print("‚è≥ Recherche dans les sources officielles...")
            
            result = agent.verify_claim(claim)
            
            # Affichage du r√©sultat
            print("\n" + "="*50)
            print("üìä R√âSULTAT DE LA V√âRIFICATION")
            print("="*50)
            
            print(f"\nüìå Affirmation : {result['claim']}")
            print(f"‚úÖ Verdict : {result['verdict']}")
            print(f"üìä Confiance : {result.get('confidence', 'N/A')}%")
            print(f"\nüìù Analyse d√©taill√©e :")
            print("-"*50)
            
            # Affiche l'analyse en la formatant
            analysis = result.get('raw_analysis', 'Pas d\'analyse disponible')
            for line in analysis.split('\n'):
                if line.strip():
                    print(f"  {line.strip()}")
            
            print("\n" + "="*50)
    
    @staticmethod
    def run_batch_mode(claims_file: str = "claims.txt"):
        """Mode batch pour traiter plusieurs claims depuis un fichier"""
        
        print(f"\nüìÇ Lecture du fichier : {claims_file}")
        
        try:
            with open(claims_file, 'r', encoding='utf-8') as f:
                claims = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"‚ùå Fichier '{claims_file}' non trouv√© !")
            print("Cr√©e un fichier 'claims.txt' avec une affirmation par ligne.")
            return
        
        print(f"üìã {len(claims)} affirmations √† v√©rifier\n")
        
        # Initialisation de l'agent
        agent = FactCheckerAgent()
        
        # Traitement batch
        results = agent.batch_verify(claims)
        
        # Sauvegarde des r√©sultats
        output_file = f"verification_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ R√©sultats sauvegard√©s dans : {output_file}")
        
        # R√©sum√©
        print("\nüìä R√âSUM√â :")
        print("-"*30)
        verified = sum(1 for r in results if "V√âRIFI√â" in r.get('verdict', '') and "NON" not in r.get('verdict', ''))
        unverified = sum(1 for r in results if "NON V√âRIFI√â" in r.get('verdict', ''))
        partial = sum(1 for r in results if "PARTIELLEMENT" in r.get('verdict', ''))
        
        print(f"‚úÖ V√©rifi√©s : {verified}")
        print(f"‚ö†Ô∏è  Partiellement v√©rifi√©s : {partial}")
        print(f"‚ùå Non v√©rifi√©s : {unverified}")


# ============================================
# MAIN - POINT D'ENTR√âE CURSOR
# ============================================

def main():
    """
    Point d'entr√©e principal pour Cursor Agent Mode
    
    Usage dans Cursor :
    1. Ouvre ce fichier dans Cursor
    2. Active le mode Agent (Cmd+Shift+P -> "Toggle Agent Mode")
    3. Lance avec : python fact_checker_agent.py
    """
    
    import sys
    
    # D√©tection du mode
    if len(sys.argv) > 1:
        mode = sys.argv[1].lower()
        
        if mode == "batch":
            # Mode batch
            file_path = sys.argv[2] if len(sys.argv) > 2 else "claims.txt"
            CursorAgentInterface.run_batch_mode(file_path)
        elif mode == "test":
            # Mode test avec exemples
            print("\nüß™ MODE TEST - Exemples de v√©rification\n")
            
            test_claims = [
                "La Tour Eiffel mesure 330 m√®tres de hauteur",
                "Emmanuel Macron est le pr√©sident de la France en 2024",
                "Le vaccin COVID-19 contient des puces 5G",
                "L'eau bout √† 100 degr√©s Celsius au niveau de la mer",
                "La Terre est plate"
            ]
            
            agent = FactCheckerAgent()
            
            for claim in test_claims:
                print(f"\n{'='*60}")
                print(f"TEST : {claim}")
                result = agent.verify_claim(claim)
                print(f"VERDICT : {result.get('verdict', 'UNKNOWN')}")
                print(f"CONFIANCE : {result.get('confidence', 'N/A')}%")
        else:
            print(f"‚ùå Mode inconnu : {mode}")
            print("Modes disponibles : interactive (d√©faut), batch, test")
    else:
        # Mode interactif par d√©faut
        CursorAgentInterface.run_interactive()


if __name__ == "__main__":
    main()
